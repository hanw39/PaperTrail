# Related Work {#sec:related}

#### Automated AI Research & Engineering.

Recent advancements in LLMs have enabled autonomous agents to tackle complex, long-horizon AI research problems, including Machine Learning Engineering (MLE) [@chan2024mle], Research Engineering [@wijk2024re], and Automated Research Replication [@starace2025paperbench]. While numerous agentic frameworks have been proposed to address these challenges [@aide2025; @toledo2025ai; @yang2025rdagent; @liu2025ml; @team2025novelseek; @li2025fm; @nam2025mle; @zhu2026toward], existing systems predominantly operate under a *monolithic paradigm*, generating expansive, single-file scripts. This approach typically results in fragile codebases that lack the modularity essential for rigorous engineering. MARS departs from this by enforcing a *repository-level paradigm* that systematically decomposes tasks into distinct, testable, and maintainable modules, mirroring professional software architecture.

**Search Algorithms in Code Generation.** Solving long-horizon AI research problems, where code execution is resource-intensive, necessitates effective search strategies for code optimization. While various algorithms have been adapted for these systems -- including greedy search [@aide2025], Monte Carlo Tree Search (MCTS) [@kocsis2006bandit; @liu2025ml], and Evolutionary search [@team2025novelseek] -- they typically optimize solely for task performance, neglecting computational cost. While recent work has introduced "budget awareness" for tool-augmented agents via external plug-ins [@liu2025budgetawaretooluseenableseffective], such methods are primarily designed for discrete actions like web search. In contrast, we introduce *Budget-aware MCTS*, which integrates an efficiency-guided reward function directly into the search tree. This allows MARS to balance the exploitation of high-performing strategies with the exploration of novel ideas, penalizing computationally expensive solutions to ensure both performance and efficiency.

::: table*
:::

**Reflective Learning and Memory.** Enabling agents to improve iteratively through environmental interaction is a rapidly evolving research area. Approaches such as Reflexion [@shinn2023reflexion] enable self-correction via verbal reinforcement derived from prior mistakes. [@tan2025prospectretrospectreflectivememory] introduce a reflective memory management framework to enhance long-term personalization in dialogue agents, and [@zhu2026toward] propose Hierarchical Cognitive Caching to distill execution traces into stable knowledge, while [@jansen-etal-2025-codescientist] cache useful codeblocks for future reuse. MARS advances this by introducing "Lesson Learning". Distinct from prior methods that primarily summarize execution logs and focus on debugging errors, our approach explicitly analyzes the causal link between *code changes* and performance variations. This comparative analysis isolates effective algorithmic changes from confounding factors, distilling high-value insights into a lesson pool to guide future exploration.

Table [\[tab:system_comparison\]](#tab:system_comparison){reference-type="ref" reference="tab:system_comparison"} summarizes the key differences between MARS and existing MLE agent frameworks.
