# Setup for Leaderboard Methods vs. Our Setup {#app:leaderboard-setup}

Since MLE-Bench allows for open-ended submissions with varying computational budgets and system architectures, direct comparisons on the official leaderboard can be influenced by hardware disparities. To ensure a fair assessment, we detail the specific hardware, time limits, and auxiliary resources used by top-performing leaderboard agents alongside our own in Table [3](#tab:leaderboard-setup){reference-type="ref" reference="tab:leaderboard-setup"}. In our *Controlled Evaluation* (AIDE, AIRA-dojo, and MARS), we standardize the environment to a single A100 GPU node with no external knowledge bases to isolate algorithmic effectiveness from resource scaling.

:::: adjustbox
width=,center

::: {#tab:leaderboard-setup}
  **Agent**                                             **Model**                                **Compute**                                                                                                                                                                             **Parallelization**                                           **Knowledge Base**
  ----------------------------------------------------- ---------------------------------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ------------------------------------------------------------- -----------------------------------------------------------------------------
  ML-Master [@liu2025ml]                                Deepseek-R1                              36 vCPUs, 512GB of RAM, and 1 A100 80GB GPU, 12-hour limit                                                                                                                              3-way parallel search                                         None
  R&D-Agent [@yang2025rdagent]                          GPT-5                                    12 vCPUs, 220GB of RAM, and 1 V100 GPU, 12-hour limit                                                                                                                                   Parallel exploration                                          None
  InternAgent [@team2025novelseek]                      Deepseek-R1                              32 vCPUs, 230 GB RAM, 1 A800 GPU, 12-hour limit                                                                                                                                         Unknown                                                       Unknown
  Famou-Agent [@li2025fm]                               Gemini-2.5-Pro                           64 vCPUs, 500GB RAM, 1 A800 GPU, 24-hour limit                                                                                                                                          Concurrent evaluation across distributed computing resource   An expert knowledge base
  Leeroo [@kapso2025]                                   Gemini-3-Pro-Preview                     150GB RAM, 24 vCPUs, 1 H100 GPU. Run for 24 hours or until a maximum budget of \$200 is reached. Stop early if the run achieves any medal according to the MLE-Bench grading library.   Executing multiple ExperimentSessions concurrently            A knowledge plane aggregates heterogeneous sources
  ML-Master 2.0 [@zhu2026toward]                        Deepseek-V3.2-Speciale                   36 vCPUs, 252GB of RAM, and two 4090-24GB GPU, 24-hour limit                                                                                                                            Parallel exploration                                          Use 407 kaggle competitions as a warm up dataset to build up a prior wisdom
  AIDE [@aide2025], AIRA-dojo [@toledo2025ai] or MARS   Gemini-2.5-Pro or Gemini-3-Pro-Preview   1 A100 GPU 40GB, 12 vCPUs, 220 GB of RAM, 24-hour limit                                                                                                                                 Non-parallel execution                                        None
  MARS+                                                 Gemini-3-Pro-Preview                     2 H100 GPUs, 48 vCPUs, 220 GB of RAM, 24-hour limit                                                                                                                                     2-way parallel search                                         None

  : Comparison of leaderboard agents' setup and our agent's setup.
:::
::::
