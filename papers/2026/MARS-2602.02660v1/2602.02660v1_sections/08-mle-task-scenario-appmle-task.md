# MLE Task Scenario {#app:mle-task}

Machine Learning Engineering (MLE) is a representative and challenging instantiation of this general problem class. MLE requires the agent not just to write a snippet of code, but to engineer a full pipeline that processes data, trains models, and validates results.

We map the general problem $\mathcal{P} = (\mathcal{I}, \mathcal{E}, \mathcal{O})$ to an MLE task $Q = (I, D, M)$, where:

- $I$ corresponds to the natural language task description ($\mathcal{I}$).

- $D$ represents the datasets ($D = \{ D_{dev}, D_{test} \}$) which form the data environment ($\mathcal{E}$).

- $M$ is the evaluation metric (e.g., Accuracy, F1-score) defining the objective ($\mathcal{O}$). Without loss of generality, we treat the optimization of $M$ as a maximization problem.

If a pre-defined validation set is not provided in the development set $D_{dev}$, the agent must partition $D_{dev}$ to create a validation set $D_{val}$ for internal evaluation, as the test set $D_{test}$ is strictly hidden.

We aim to build an MLE agent $\mathcal{A}$ that explores a space of possible solutions and outputs a final executable solution $s$. We define the solution $s$ as a structured software repository comprising the distinct code modules, dependencies, and entry points required to orchestrate the end-to-end pipeline.

The performance of a solution $s$ is quantified by the metric function $f(s, D, M) \in \mathbb{R}$. While the ultimate goal is to maximize performance on the unseen test set $D_{test}$, the agent must rely on a proxy objective using the validation set $D_{val}$. The optimization objective becomes: $$\begin{align}
    s^* = \mathop{\mathrm{arg\,max}}_{s \in \mathcal{S}_{\mathcal{A}}} \quad f(s, D_{test}, M), \quad s.t. \quad C(s) \leq T
\end{align}$$ where $T$ is the wall-clock time budget, $\mathcal{S}_{\mathcal{A}}$ is the set of candidate solutions generated by agent $\mathcal{A}$ given task $Q$, and $C(s)$ denotes the total wall-clock time consumed by the agent to search for the solution $s$. Since $D_{test}$ is unobservable, the agent optimizes via $f(s, D_{val}, M)$.
